[SERVICE]
    Flush         5
    Daemon        off
    Log_Level     info
    Parsers_File  parsers.conf
    HTTP_Server   On
    HTTP_Listen   0.0.0.0
    HTTP_Port     2020

# Input from Docker containers
[INPUT]
    Name              forward
    Listen            0.0.0.0
    Port              24224
    Buffer_Chunk_Size 1M
    Buffer_Max_Size   6M

# Input from Docker logs (JSON format)
[INPUT]
    Name        tail
    Path        /var/lib/docker/containers/*/*.log
    Parser      docker
    Tag         docker.*
    Refresh_Interval 5
    Mem_Buf_Limit    50MB
    Skip_Long_Lines  On

# Input from application logs (if your apps write to files)
[INPUT]
    Name        tail
    Path        /var/log/app/*.log
    Tag         app.*
    Refresh_Interval 5
    Mem_Buf_Limit    50MB

# Filter to add metadata
[FILTER]
    Name                kubernetes
    Match               docker.*
    Kube_URL            unix:///var/run/docker.sock
    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
    Merge_Log           On
    Keep_Log            Off

# Filter to parse and enrich logs
[FILTER]
    Name    modify
    Match   *
    Add     cluster_name microservices
    Add     environment production

# Output to S3
[OUTPUT]
    Name                         s3
    Match                        *
    bucket                       ${S3_BUCKET}
    region                       ${AWS_DEFAULT_REGION}
    endpoint                     ${S3_BUCKET_ENDPOINT}
    total_file_size              50M
    s3_key_format                /logs/%Y/%m/%d/%H/fluent-bit-logs-%Y%m%d-%H%M%S
    s3_key_format_tag_delimiters .-
    upload_timeout               10m
    use_put_object               On
    compression                  gzip
    content_type                 application/gzip
    send_content_md5             true

# Output to stdout for debugging (optional)
[OUTPUT]
    Name   stdout
    Match  *
    Format json_lines